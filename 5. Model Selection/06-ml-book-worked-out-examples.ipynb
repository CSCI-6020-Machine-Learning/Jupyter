{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**: to learn how to perform linear model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textbook page number 262 -- 263, problem 8\n",
    "\n",
    "In this exercise, we will generate simulated data, and will then use this data to perform best subset selection.\n",
    "\n",
    "This question has multiple parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) \n",
    "\n",
    "Use the **rnorm()** function to generate a predictor $X$ of length $n = 100$, as well as a noise vector $\\epsilon$ of length $n = 100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure reproducibility\n",
    "set.seed(1)\n",
    "\n",
    "# predictor vector\n",
    "X = rnorm(100)\n",
    "\n",
    "head(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise vector\n",
    "epsilon = rnorm(100)\n",
    "\n",
    "head(epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) \n",
    "\n",
    "Generate a response vector $Y$ of length $n = 100$ according to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\epsilon $$\n",
    "\n",
    "where $\\beta_0$, $\\beta_1$, $\\beta_2$, and $\\beta_3$ are constants of your choice.\n",
    "\n",
    "Select $\\beta_0 = 12$, $\\beta_1 = 2$, $\\beta_2 = 3.95$, and $\\beta_3 = 4.23$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Response vector:**\n",
    "    \n",
    "Y = 12 + 2 * X + 3.95 * X^2 + 4.23 * X^3 + epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) \n",
    "\n",
    "Use the **regsubsets()** function to perform best subset selection in order to choose the best model containing the predictors $X, X^2, \\ldots ,X^{10}$. What is the best model obtained according to $C_p$, BIC, and adjusted $R^2$? Show some plots to provide evidence for your answer, and report the coefficients of the best model obtained. Note you will need to use the **data.frame()** function to create a single data set containing both $X$ and $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regsubsets() is in leaps library\n",
    "library(leaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a dataset of Y and X vectors\n",
    "data.set = data.frame(\"y\" = Y, \"x\" = X)\n",
    "\n",
    "# all subsets regression -- poly() simplifies syntax -- see chapter 7\n",
    "model.1 = regsubsets(y ~ poly(x, 10, raw = T), data = data.set, nvmax = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model summary\n",
    "model.summary = summary(model.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary() returns R^2, RSS, adjusted R^2, Cp, and BIC\n",
    "names(model.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model size for best Cp, BIC and adj R^2\n",
    "\n",
    "# model with smallest Cp\n",
    "which.min(model.summary$cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with smallest BIC\n",
    "which.min(model.summary$bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with largest adj R^2\n",
    "which.max(model.summary$adjr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot subset size vs. smallest Cp value for the subset size class\n",
    "plot(model.summary$cp, xlab = \"Subset Size\", ylab = \"Cp\", pch = 20, type = \"l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset size 4 model has the smallest Cp value\n",
    "points(4, model.summary$cp[4], pch = 4, col = \"red\", lwd = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot subset size vs. smallest BIC value for the subset size class\n",
    "plot(model.summary$bic, xlab = \"Subset Size\", ylab = \"BIC\", pch = 20, type = \"l\")\n",
    "# subset size 3 model has the smallest BIC value\n",
    "points(3, model.summary$bic[3], pch = 4, col = \"red\", lwd = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot subset size vs. largest adjusted R^2 value for the subset size class\n",
    "plot(model.summary$adjr2, xlab = \"Subset Size\", ylab = \"Adjusted R2\", pch = 20, type = \"l\")\n",
    "# subset size 4 model has the largest adjusted R^2 value\n",
    "points(4, model.summary$adjr2[4], pch = 4, col = \"red\", lwd = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all three measures point to subset size 3 or 4 models\n",
    "\n",
    "# regsubsets() function has a built-in plot() command which can be used to display the selected variables for the best model\n",
    "plot(model.1, scale = \"r2\")\n",
    "plot(model.1, scale = \"adjr2\")\n",
    "plot(model.1, scale = \"Cp\")\n",
    "plot(model.1, scale = \"bic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print coefficients of subset size 3 model\n",
    "coefficients(model.1, id = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print coefficients of subset size 4 model. coef() and coefficients() synonyms?\n",
    "coef(model.1, id = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) \n",
    "\n",
    "Repeat (c), using forward stepwise selection and also using backward stepwise selection. How does your answer compare to the results in (c)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward stepwise selection\n",
    "model.fwd = regsubsets(y ~ poly(x, 10, raw = T), data = data.set, nvmax = 10, method = \"forward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward stepwise selection\n",
    "model.bwd = regsubsets(y ~ poly(x, 10, raw = T), data = data.set, nvmax = 10, method = \"backward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd.model.summary = summary(model.fwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwd.model.summary = summary(model.bwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cp measure\n",
    "which.min(fwd.model.summary$cp)\n",
    "which.min(bwd.model.summary$cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIC measure\n",
    "which.min(fwd.model.summary$bic)\n",
    "which.min(bwd.model.summary$bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusted R^2 measure\n",
    "which.max(fwd.model.summary$adjr2)\n",
    "which.max(bwd.model.summary$adjr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot statistics in a 3 row by 2 column layout\n",
    "par(mfrow=c(3, 2))\n",
    "\n",
    "plot(fwd.model.summary$cp, xlab = \"Subset Size\", ylab = \"Forward Cp\", pch = 20, type = \"l\")\n",
    "\n",
    "points(4, fwd.model.summary$cp[4], pch = 4, col = \"red\", lwd = 7)\n",
    "\n",
    "\n",
    "plot(bwd.model.summary$cp, xlab = \"Subset Size\", ylab = \"Backward Cp\", pch = 20, type = \"l\")\n",
    "\n",
    "points(4, bwd.model.summary$cp[4], pch = 4, col = \"red\", lwd = 7)\n",
    "\n",
    "plot(fwd.model.summary$bic, xlab = \"Subset Size\", ylab = \"Forward BIC\", pch = 20, type = \"l\")\n",
    "\n",
    "points(3, fwd.model.summary$bic[3], pch = 4, col = \"red\", lwd = 7)\n",
    "\n",
    "plot(bwd.model.summary$bic, xlab = \"Subset Size\", ylab = \"Backward BIC\", pch = 20, type = \"l\")\n",
    "\n",
    "points(3, bwd.model.summary$bic[3], pch = 4, col = \"red\", lwd = 7)\n",
    "\n",
    "plot(fwd.model.summary$adjr2, xlab = \"Subset Size\", ylab = \"Forward Adjusted R2\", pch = 20, type = \"l\")\n",
    "\n",
    "points(4, fwd.model.summary$adjr2[4], pch = 4, col = \"red\", lwd = 7)\n",
    "\n",
    "plot(bwd.model.summary$adjr2, xlab = \"Subset Size\", ylab = \"Backward Adjusted R2\", pch = 20, type = \"l\")\n",
    "\n",
    "points(4, bwd.model.summary$adjr2[4], pch = 4, col = \"red\", lwd=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size 3 model has smallest BIC, forward stepwise\n",
    "coefficients(model.fwd, id = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size 4 model has smallest Cp and largest adjusted R^2, forward stepwise\n",
    "coefficients(model.fwd, id = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size 3 model has smallest BIC, backward stepwise\n",
    "coefficients(model.bwd, id = 3)\n",
    "\n",
    "# size 4 model has smallest Cp and largest adjusted R^2, backward stepwise\n",
    "coefficients(model.bwd, id = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) \n",
    "Now fit a lasso model to the simulated data, again using $X, X^2, \\ldots ,X^{10}$ as predictors. Use cross-validation to select the optimal value of $\\lambda$. Create plots of the cross-validation error as a function of $\\lambda$. Report the resulting coefficient estimates, and discuss the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso is in glmnet library\n",
    "library(glmnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame to matrix format\n",
    "x.matrix = model.matrix(y ~ poly(x, 10, raw = T), data = data.set)[, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build lasso model\n",
    "lasso.model = cv.glmnet(x.matrix, Y, alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select optimal lambda\n",
    "optimal.lambda = lasso.model$lambda.min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print tuning parameter\n",
    "optimal.lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot lasso model\n",
    "plot(lasso.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model on entire data\n",
    "optimal.model = glmnet(x.matrix, Y, alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(optimal.model, s = optimal.lambda, type = \"coefficients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) \n",
    "Now generate a response vector Y according to the model $ Y = \\beta_0 + \\beta_7 X^7 + \\epsilon,$ and perform best subset selection and the lasso. Discuss the results obtained. Select $\\beta_0 = 12$, $\\beta_7 = 6$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new response vector Y\n",
    "Y = 12 + 6 * X^10 + epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a dataset of Y and X vectors\n",
    "data.set = data.frame(\"y\" = Y, \"x\" = X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regsubsets() is in leaps library\n",
    "library(leaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all subsets regression -- poly() simplifies syntax -- see chapter 7\n",
    "model.1 = regsubsets(y ~ poly(x, 10, raw = T), data = data.set, nvmax = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model summary\n",
    "model.summary = summary(model.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary() returns R^2, RSS, adjusted R^2, Cp, and BIC\n",
    "names(model.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model size for best Cp, BIC and adj R^2\n",
    "\n",
    "# model with smallest Cp\n",
    "which.min(model.summary$cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with smallest BIC\n",
    "which.min(model.summary$bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with largest adj R^2\n",
    "which.max(model.summary$adjr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot subset size vs. smallest Cp value for the subset size class\n",
    "plot(model.summary$cp, xlab = \"Subset Size\", ylab = \"Cp\", pch = 20, type = \"l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset size 2 model has the smallest Cp value\n",
    "points(2, model.summary$cp[2], pch = 4, col = \"red\", lwd = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot subset size vs. smallest BIC value for the subset size class\n",
    "plot(model.summary$bic, xlab = \"Subset Size\", ylab = \"BIC\", pch = 20, type = \"l\")\n",
    "# subset size 1 model has the smallest BIC value\n",
    "points(1, model.summary$bic[1], pch = 4, col = \"red\", lwd = 7)\n",
    "\n",
    "# plot subset size vs. largest adjusted R^2 value for the subset size class\n",
    "plot(model.summary$adjr2, xlab = \"Subset Size\", ylab = \"Adjusted R2\", pch = 20, type = \"l\")\n",
    "# subset size 2 model has the largest adjusted R^2 value\n",
    "points(2, model.summary$adjr2[2], pch = 4, col = \"red\", lwd = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all three measures point to subset size 2 or 1 models\n",
    "\n",
    "# regsubsets() function has a built-in plot() command which can be used to display the selected variables for the best model\n",
    "plot(model.1, scale = \"r2\")\n",
    "plot(model.1, scale = \"adjr2\")\n",
    "plot(model.1, scale = \"Cp\")\n",
    "plot(model.1, scale = \"bic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print coefficients of subset size 1 model\n",
    "coefficients(model.1, id = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print coefficients of subset size 2 model\n",
    "coefficients(model.1, id = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textbook page number 263, problem 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will predict the number of applications received using the other variables in the **College** data set. There are multiple parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) \n",
    "Split the data set into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# College data is in ISLR package\n",
    "library(ISLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure reproducibility\n",
    "set.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(College)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(College)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(College)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are there any missing values?\n",
    "sum(is.na(College))\n",
    "\n",
    "# no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample dim(College)[1]/2) times for training data\n",
    "train.indices = sample(1:dim(College)[1], dim(College)[1]/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# those indices that are not in training form the test indices\n",
    "test.indices = -train.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract training data\n",
    "train.data = College[train.indices, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract test data\n",
    "test.data = College[test.indices, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) \n",
    "\n",
    "Fit a linear model using least squares on the training set, and report the test error obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict number of applications (Apps) received\n",
    "\n",
    "# build the model\n",
    "lm.model = lm(Apps ~ ., data = train.data)\n",
    "\n",
    "# use the model to predict on the test dataset\n",
    "lm.model.pred = predict(lm.model, test.data)\n",
    "\n",
    "# compute mean test error\n",
    "mean((test.data[, \"Apps\"] - lm.model.pred)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) \n",
    "Fit a ridge regression model on the training set, with $\\lambda$ chosen by cross-validation. Report the test error obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(glmnet)\n",
    "\n",
    "# create training data matrix\n",
    "train.matrix = model.matrix(Apps ~ ., data = train.data)\n",
    "\n",
    "# create test data matrix\n",
    "test.matrix = model.matrix(Apps ~ ., data = test.data)\n",
    "\n",
    "# lambda values grid\n",
    "grid = 10 ^ seq(4, -2, length = 100)\n",
    "\n",
    "# build ridge regression model\n",
    "ridge.model = cv.glmnet(train.matrix, train.data[, \"Apps\"], alpha = 0, lambda = grid, thresh = 1e-12)\n",
    "\n",
    "# find best/optimal lambda\n",
    "optimal.lambda = ridge.model$lambda.min\n",
    "\n",
    "# print best/optimal lambda\n",
    "optimal.lambda\n",
    "\n",
    "# make predictions on test data using the ridge model\n",
    "ridge.model.pred = predict(ridge.model, newx = test.matrix, s = optimal.lambda)\n",
    "\n",
    "# compute mean test error\n",
    "mean((test.data[, \"Apps\"] - ridge.model.pred)^2)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) \n",
    "\n",
    "Fit a lasso model on the training set, with $\\lambda$ chosen by cross-validation. Report the test error obtained, along with the number of non-zero coefficient estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.model = cv.glmnet(train.matrix, train.data[, \"Apps\"], alpha = 1, lambda = grid, thresh = 1e-12)\n",
    "\n",
    "optimal.lambda = lasso.model$lambda.min\n",
    "\n",
    "optimal.lambda\n",
    "\n",
    "lasso.model.pred = predict(lasso.model, newx = test.matrix, s = optimal.lambda)\n",
    "\n",
    "mean((test.data[, \"Apps\"] - lasso.model.pred)^2)\n",
    "\n",
    "\n",
    "# lasso model on the full dataset\n",
    "lasso.model.2 = glmnet(model.matrix(Apps ~ ., data = College), College[ , \"Apps\"], alpha = 1)\n",
    "\n",
    "predict(lasso.model.2, s = optimal.lambda, type = \"coefficients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) \n",
    "\n",
    "Fit a Principal Component Regression (PCR) model on the training set, with $M$ chosen by cross-validation. Report the test error obtained, along with the value of $M$ selected by cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(pls)\n",
    "\n",
    "pcr.model = pcr(Apps ~ ., data = train.data, scale = T, validation = \"CV\")\n",
    "\n",
    "validationplot(pcr.model, val.type = \"MSEP\")\n",
    "\n",
    "pcr.model.pred = predict(pcr.model, test.data, ncomp = 10)\n",
    "\n",
    "mean((test.data[ , \"Apps\"] - pcr.model.pred)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) \n",
    "\n",
    "Fit a Partial Least Squares (PLS) model on the training set, with $M$ chosen by cross-validation. Report the test error obtained, along with the value of $M$ selected by cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls.model = plsr(Apps ~ ., data = train.data, scale = T, validation = \"CV\")\n",
    "\n",
    "# mean squared error of prediction (MSEP)\n",
    "validationplot(pls.model, val.type = \"MSEP\")\n",
    "\n",
    "pls.model.pred = predict(pls.model, test.data, ncomp = 10)\n",
    "\n",
    "mean((test.data[ , \"Apps\"] - pls.model.pred)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g) \n",
    "\n",
    "Comment on the results obtained. How accurately can we predict the number of college applications received? Is there much difference among the test errors resulting from these five approaches?\n",
    "\n",
    "Results for Ordinary Least Squares (OLS), Ridge, and Lasso are similar. Lasso reduces the \\emph{F.Undergrad}, \\emph{Books}, and \\emph{Personal} variables to zero. Also, it shrinks coefficients of other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.avg = mean(test.data[ , \"Apps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2 = 1 - (RSS/TSS)\n",
    "\n",
    "tss = mean((test.data[ , \"Apps\"] - test.avg)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinary least squares model\n",
    "lm.test.r.squared = 1 - mean((test.data[ , \"Apps\"] - lm.model.pred)^2) / tss\n",
    "\n",
    "lm.test.r.squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge regression model\n",
    "ridge.test.r.squared = 1 - mean((test.data[ , \"Apps\"] - ridge.model.pred)^2) / tss\n",
    "\n",
    "ridge.test.r.squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso regression model\n",
    "lasso.test.r.squared = 1 - mean((test.data[ , \"Apps\"] - lasso.model.pred)^2) / tss\n",
    "\n",
    "lasso.test.r.squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# principal components regression model\n",
    "pcr.test.r.squared = 1 - mean((test.data[ , \"Apps\"] - pcr.model.pred)^2) / tss\n",
    "\n",
    "pcr.test.r.squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial least squares model\n",
    "pls.test.r.squared = 1 - mean((test.data[ , \"Apps\"] - pls.model.pred)^2) / tss\n",
    "\n",
    "pls.test.r.squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot R^2 for all models\n",
    "barplot( c(lm.test.r.squared, ridge.test.r.squared, lasso.test.r.squared, pcr.test.r.squared, pls.test.r.squared), col = \"purple\", names.arg = c(\"OLS\", \"Ridge\", \"Lasso\", \"PCR\", \"PLS\"), main = \"Test R-squared Values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test $R^2$ for all models (except PCR) is about 0.9. While PLS $R^2$ is slightly higher than $R^2$ of other models,  PCR has a smaller test $R^2$ of about 0.8. With the exception of PCR, all models predict college applications with high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
